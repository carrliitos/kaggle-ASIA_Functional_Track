{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95290373-34f0-48dc-a12d-4a848e442334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import set_config\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc1253fb-efab-41f2-b474-9e3db5fb4127",
   "metadata": {},
   "outputs": [],
   "source": [
    "VER = 21            # VERSION NAME FOR SAVED MODEL FILES\n",
    "SEED = 42           # TRAIN RANDOM SEED\n",
    "NAN_VALUE = -127    # FILL NAN VALUE - will fit in int8\n",
    "FOLDS = 5           # FOLDS PER MODEL\n",
    "project_dir = \"../\" # PROJECT FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300cf7d2-d79d-4a40-9c52-10fc6805e50a",
   "metadata": {},
   "source": [
    "## XGBoost Regressor with Randomized Search Hypertuning\n",
    "\n",
    "We train an XGBoost model using randomized search for hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a69d9a9a-60bc-4bb1-a247-67e367622964",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw_path = \"../data-raw\"\n",
    "\n",
    "train_features_csv = f\"{data_raw_path}/train_features.csv\"\n",
    "train_outcomes_functional_csv = f\"{data_raw_path}/train_outcomes_functional.csv\"\n",
    "\n",
    "test_features_csv = f\"{data_raw_path}/test_features.csv\"\n",
    "test_outcomes_csv = f\"{data_raw_path}/test_outcomes_Fun_template_update.csv\"\n",
    "\n",
    "metadata_csv = f\"{data_raw_path}/metadata.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7b6c04b-054f-4334-ab36-5107cd032062",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_df = pd.read_csv(train_features_csv)\n",
    "train_outcomes_df = pd.read_csv(train_outcomes_functional_csv)\n",
    "\n",
    "test_features_df = pd.read_csv(test_features_csv)\n",
    "test_outcomes_df = pd.read_csv(test_outcomes_csv)\n",
    "\n",
    "metadata_df = pd.read_csv(metadata_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15f4c837-99ea-4e06-a5f9-644ed5dd4294",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = train_features_df.merge(train_outcomes_df, on=\"PID\", how=\"inner\")\n",
    "full_training_df = training_df.merge(metadata_df, on=\"PID\", how=\"inner\")\n",
    "\n",
    "testing_df = test_features_df.merge(test_outcomes_df, on=\"PID\", how=\"inner\")\n",
    "full_testing_df = testing_df.merge(metadata_df, on=\"PID\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8803c4aa-4b6f-40c5-baf5-6bb950e2e275",
   "metadata": {},
   "source": [
    "## Subsetting only Week 1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cba1fd9-2c77-411d-b61f-205ea89d6788",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variables = [\"PID\", \"modben\", \"age_category\", \"sexcd\", \"bmi_category\", \"srdecc1\", \"surgcd1\", \"spcsuc1\", \"scdecc1\", \n",
    "                    \"hemccd1\", \"mhpsyccd\", \"mhneurcd\", \"mhcardcd\", \"mhmetacd\", \"tx1_r\", \"ais1\", \"elbfll01\", \"wrextl01\", \n",
    "                    \"elbexl01\", \"finfll01\", \"finabl01\", \"hipfll01\", \"kneexl01\", \"ankdol01\", \"gretol01\", \"ankpll01\", \n",
    "                    \"elbflr01\", \"wrextr01\", \"elbexr01\", \"finflr01\", \"finabr01\", \"hipflr01\", \"kneetr01\", \"ankdor01\", \n",
    "                    \"gretor01\", \"ankplr01\", \"c2ltl01\", \"c3ltl01\", \"c4ltl01\", \"c5ltl01\", \"c6ltl01\", \"c7ltl01\", \"c8ltl01\", \n",
    "                    \"t1ltl01\", \"t2ltl01\", \"t3ltl01\", \"t4ltl01\", \"t5ltl01\", \"t6ltl01\", \"t7ltl01\", \"t8ltl01\", \"t9ltl01\", \n",
    "                    \"t10ltl01\", \"t11ltl01\", \"t12ltl01\", \"l1ltl01\", \"l2ltl01\", \"l3ltl01\", \"l4ltl01\", \"l5ltl01\", \"s1ltl01\", \n",
    "                    \"s2ltl01\", \"s3ltl01\", \"s45ltl01\", \"c2ltr01\", \"c3ltr01\", \"c4ltr01\", \"c5ltr01\", \"c6ltr01\", \"c7ltr01\", \n",
    "                    \"c8ltr01\", \"t1ltr01\", \"t2ltr01\", \"t3ltr01\", \"t4ltr01\", \"t5ltr01\", \"t6ltr01\", \"t7ltr01\", \"t8ltr01\", \n",
    "                    \"t9ltr01\", \"t10ltr01\", \"t11ltr01\", \"t12ltr01\", \"l1ltr01\", \"l2ltr01\", \"l3ltr01\", \"l4ltr01\", \"l5ltr01\", \n",
    "                    \"s1ltr01\", \"s2ltr01\", \"s3ltr01\", \"s45ltr01\", \"c2ppl01\", \"c3ppl01\", \"c4ppl01\", \"c5ppl01\", \"c6ppl01\", \n",
    "                    \"c7ppl01\", \"c8ppl01\", \"t1ppl01\", \"t2ppl01\", \"t3ppl01\", \"t4ppl01\", \"t5ppl01\", \"t6ppl01\", \"t7ppl01\", \n",
    "                    \"t8ppl01\", \"t9ppl01\", \"t10ppl01\", \"t11ppl01\", \"t12ppl01\", \"l1ppl01\", \"l2ppl01\", \"l3ppl01\", \"l4ppl01\", \n",
    "                    \"l5ppl01\", \"s1ppl01\", \"s2ppl01\", \"s3ppl01\", \"s45ppl01\", \"c2ppr01\", \"c3ppr01\", \"c4ppr01\", \"c5ppr01\", \n",
    "                    \"c6ppr01\", \"c7ppr01\", \"c8ppr01\", \"t1ppr01\", \"t2ppr01\", \"t3ppr01\", \"t4ppr01\", \"t5ppr01\", \"t6ppr01\", \n",
    "                    \"t7ppr01\", \"t8ppr01\", \"t9ppr01\", \"t10ppr01\", \"t11ppr01\", \"t12ppr01\", \"l1ppr01\", \"l2ppr01\", \"l3ppr01\", \n",
    "                    \"l4ppr01\", \"l5ppr01\", \"s1ppr01\", \"s2ppr01\", \"s3ppr01\", \"s45ppr01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b60dc03f-6582-4b05-925a-bd65e94f4083",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = full_training_df[target_variables]\n",
    "testing_df = full_testing_df[target_variables]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb72ac04-3b09-4146-a149-3de419f414ae",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d169239f-f813-4114-bedc-6f3440c2a1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_feature_engineering(df):\n",
    "    \"\"\"\n",
    "    Perform feature engineering by aggregating numerical and categorical features \n",
    "    over the 'PID' identifier. This function:\n",
    "    \n",
    "    1. Identifies and separates categorical and numerical features.\n",
    "    2. Aggregates numerical features using mean, std, min, max, and last observed value.\n",
    "    3. Aggregates categorical features using count, last observed value, and number of unique values.\n",
    "    4. Concatenates aggregated features into a single DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ==========\n",
    "    df (pd.DataFrame): Input DataFrame containing patient-level records with a 'PID' column and features.\n",
    "\n",
    "    Returns\n",
    "    =======\n",
    "    pd.DataFrame: Aggregated DataFrame with engineered features indexed by 'PID'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Fill NA values\n",
    "    df = df.fillna(NAN_VALUE).copy()\n",
    "\n",
    "    # Exclude identifier and target from the feature list\n",
    "    all_cols = [col for col in list(df.columns) if col not in [\"PID\", \"modben\"]]\n",
    "\n",
    "    # Predefined list of categorical features\n",
    "    category_feats = [\"age_category\", \"sexcd\", \"bmi_category\", \"srdecc1\", \"surgcd1\", \"spcsuc1\", \"scdecc1\", \n",
    "                      \"hemccd1\", \"mhpsyccd\", \"mhneurcd\", \"mhcardcd\", \"mhmetacd\", \"tx1_r\", \"ais1\"]\n",
    "\n",
    "    # Treat remaining features as numeric\n",
    "    num_feats = [col for col in all_cols if col not in category_feats]\n",
    "\n",
    "    # Aggregate numeric features\n",
    "    test_num_agg = df.groupby(\"PID\")[num_feats].agg(['mean', 'std', 'min', 'max', 'last'])\n",
    "    test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n",
    "\n",
    "    # Aggregate categorical features\n",
    "    test_cat_agg = df.groupby(\"PID\")[category_feats].agg(['count', 'last', 'nunique'])\n",
    "    test_cat_agg.columns = ['_'.join(x) for x in test_cat_agg.columns]\n",
    "\n",
    "    # Combine numeric and categorical aggregates, and clean up.\n",
    "    df = pd.concat([test_num_agg, test_cat_agg], axis=1)\n",
    "    del test_num_agg, test_cat_agg\n",
    "    print(f\"Shape after engineering: {df.shape}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7fc206a-4415-4e10-abc0-b12fb3cb7a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after engineering: (582, 702)\n",
      "Shape after engineering: (118, 702)\n"
     ]
    }
   ],
   "source": [
    "train = process_and_feature_engineering(training_df)\n",
    "test = process_and_feature_engineering(testing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1007ae98-171e-4e93-914a-ef8e7d5e827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.sort_index().reset_index()\n",
    "test = test.sort_index().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3b6849-a6ec-40d4-a4b3-a1f6b5d56635",
   "metadata": {},
   "source": [
    "## X and Y Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fc49ada-78eb-4e33-ac14-6b12102dee78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(train_outcomes_df, on=\"PID\", how=\"inner\")\n",
    "train = train.drop(\"time\", axis=1)\n",
    "\n",
    "test = test.merge(test_outcomes_df, on=\"PID\", how=\"inner\")\n",
    "test = test.drop(\"time-DELETE THIS COLUMN FOR SUBMISSION\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74ca5212-282e-4bab-9a83-0bec90eb0ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure we have a category dtype\n",
    "for col in train.select_dtypes(include='object').columns:\n",
    "    train[col] = train[col].astype('category')\n",
    "\n",
    "for col in test.select_dtypes(include='object').columns:\n",
    "    test[col] = test[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bab37a8-9f68-48c4-b49b-191c26305a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['modben'] != 9.0].copy()\n",
    "train['modben'] = train['modben'].astype(int) - 1\n",
    "train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ecec074-f5c4-4a20-b29c-b1779f28468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.drop(\"modben\", axis=1)\n",
    "y_train = train[\"modben\"]\n",
    "\n",
    "x_test = train.drop(\"modben\", axis=1)\n",
    "y_test = train[\"modben\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e97008-7239-40ac-964b-a01d2c5f7336",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d491d6ab-0638-43ff-afc8-631666a1fd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix, \n",
    "    accuracy_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score, \n",
    "    roc_curve, \n",
    "    auc, \n",
    "    precision_recall_curve\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(y_true, y_pred, title, project_dir, version):\n",
    "    \"\"\"\n",
    "    Evaluate a model using various metrics and generate precision-recall and ROC curves.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true (array-like): True labels.\n",
    "    - y_pred (array-like): Predicted labels or class probabilities.\n",
    "    - title (str): Title for the evaluation.\n",
    "    - project_dir (str): Project directory.\n",
    "    - version (int): Current model version.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if len(y_true) != len(y_pred):\n",
    "            raise ValueError(\"Mismatched dimensions of y_true and y_pred.\")\n",
    "\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        report = classification_report(y_true, y_pred)\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "        recall = recall_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "\n",
    "        print(f\"\\n{title if title else 'Model Evaluation'}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(\"Confusion Matrix:\\n\", cm)\n",
    "        print(f\"Precision (weighted): {precision:.4f}\")\n",
    "        print(f\"Recall (weighted):    {recall:.4f}\")\n",
    "        print(f\"F1 Score (weighted):  {f1:.4f}\")\n",
    "        print(\"Classification Report:\\n\", report)\n",
    "\n",
    "        # Optional: Precision-Recall and ROC curves\n",
    "        # Only works for binary classification or if probabilities are provided for multiclass\n",
    "        unique_classes = np.unique(y_true)\n",
    "        if len(unique_classes) == 2:\n",
    "            if hasattr(y_pred, \"shape\") and len(y_pred.shape) == 2 and y_pred.shape[1] > 1:\n",
    "                y_pred_scores = y_pred[:, 1]\n",
    "            else:\n",
    "                y_pred_scores = y_pred  # Must be probabilities for PR/ROC\n",
    "\n",
    "            pr_precision, pr_recall, _ = precision_recall_curve(y_true, y_pred_scores)\n",
    "            plt.figure()\n",
    "            plt.plot(pr_recall, pr_precision, color=\"darkorange\", lw=2)\n",
    "            plt.xlabel(\"Recall\")\n",
    "            plt.ylabel(\"Precision\")\n",
    "            plt.title(f\"{title}: Precision-Recall Curve\")\n",
    "            plt.savefig(f\"{project_dir}/{title}_PRC-v{version}.png\")\n",
    "\n",
    "            fpr, tpr, _ = roc_curve(y_true, y_pred_scores)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.figure()\n",
    "            plt.plot(fpr, tpr, color=\"darkorange\", lw=2, label=f\"ROC curve (area = {roc_auc:.2f})\")\n",
    "            plt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
    "            plt.xlabel(\"False Positive Rate\")\n",
    "            plt.ylabel(\"True Positive Rate\")\n",
    "            plt.title(f\"{title}: Receiver Operating Characteristic Curve\")\n",
    "            plt.legend(loc=\"lower right\")\n",
    "            plt.savefig(f\"{project_dir}/{title}_ROC-v{version}.png\")\n",
    "        else:\n",
    "            print(\"Skipping PR and ROC curve generation (requires binary classification).\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during model evaluation: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bca74694-0bf9-423d-807d-8f327f6aa63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "def export_model(model, model_name, save_path):\n",
    "    \"\"\"\n",
    "    Export the trained model for serving predictions.\n",
    "\n",
    "    Parameters:\n",
    "    - model (Model): Trained model.\n",
    "    - model_name (str): Name of the model for logging purposes.\n",
    "    - save_path (str): Path to save the exported model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Saving model '{model_name}' to '{save_path}'\")\n",
    "        with open(save_path, \"wb\") as save_file:\n",
    "            joblib.dump(model, save_file)\n",
    "        print(f\"Model '{model_name}' successfully saved to '{save_path}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during model export for '{model_name}': {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0513bf2-f7df-45c3-8eca-3f6690577801",
   "metadata": {},
   "source": [
    "## Train XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81ed55a2-b13d-4225-a4e1-f8f67374366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_classifier = {\n",
    "    \"colsample_bytree\": 0.5,\n",
    "    \"max_depth\": 2,\n",
    "    \"min_child_weight\": 2,\n",
    "    \"n_estimators\": 300,\n",
    "    \"subsample\": 0.55,\n",
    "    \"gamma\": 10,\n",
    "    \"eta\": 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d91366e8-be79-4e60-b358-61dc5ec94f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_parameters_grid = {\n",
    "    \"n_estimators\": stats.randint(xgboost_classifier[\"n_estimators\"] - 60, xgboost_classifier[\"n_estimators\"] + 100),\n",
    "    \"subsample\": stats.uniform(max(0, xgboost_classifier[\"subsample\"] - 0.2), 0.05),\n",
    "    \"max_depth\": stats.randint(xgboost_classifier[\"max_depth\"] - 2, xgboost_classifier[\"max_depth\"] + 2),\n",
    "    \"colsample_bytree\": stats.uniform(xgboost_classifier[\"colsample_bytree\"] - 0.2, 0.2),\n",
    "    \"min_child_weight\": stats.randint(max(1, xgboost_classifier[\"min_child_weight\"] - 1), xgboost_classifier[\"min_child_weight\"] + 2),\n",
    "    \"gamma\": stats.uniform(xgboost_classifier[\"gamma\"], 0.2),\n",
    "    \"eta\": stats.uniform(xgboost_classifier[\"eta\"], 0.2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa3f043f-9df1-439e-ab55-f194ff8a740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost(x, y, parameters_grid, version, cross_val=5, scoring=\"accuracy\", \n",
    "                  n_jobs=-1, error_score=\"raise\", verbose=10, dir=project_dir):\n",
    "    \"\"\"\n",
    "    Train an XGBoost model using randomized search for hyperparameter tuning.\n",
    "\n",
    "    Parameters\n",
    "    ==========\n",
    "    - x (pd.DataFrame): Input features.\n",
    "    - y (pd.Series): Labels.\n",
    "    - parameters_grid (dict): Hyperparameter grid for randomized search.\n",
    "    - version (int): Current working version.\n",
    "    - cross_val (int, optional): Number of cross-validation folds. Default is 5.\n",
    "    - scoring (str, optional): Scoring strategy for cross-validation. Default is \"accuracy\".\n",
    "    - n_jobs (int, optional): Number of jobs to run in parallel during cross-validation. Default is -1 (use all processors).\n",
    "    - error_score (str or numeric, optional): Value to assign to the score if an error occurs in cross-validation. Default is \"raise\".\n",
    "    - verbose (int, optional): Verbosity level. Default is 10.\n",
    "    - dir (str, optional): Directory to save cross-validation results. Default is the current directory.\n",
    "\n",
    "    Returns\n",
    "    =======\n",
    "    - best_params (dict): Best hyperparameters found during the search.\n",
    "    \"\"\"\n",
    "    print(f\"Parameters Grid: {parameters_grid}\")\n",
    "    print(f\"{cross_val}-fold cross-validation\")\n",
    "    print(f\"Scoring strategy: {scoring}\")\n",
    "    print(f\"Number of jobs to run in parallel: {n_jobs}\")\n",
    "    print(f\"Error score: {error_score}\")\n",
    "    print(f\"Verbosity: {verbose}\")\n",
    "\n",
    "    positive_instances = np.sum(y == 1)\n",
    "    negative_instances = np.sum(y == 0)\n",
    "    ratio = negative_instances / positive_instances\n",
    "    print(f\"Weight statistics: positive instances={positive_instances}\")\n",
    "    print(f\"Weight statistics: negative instances={negative_instances}\")\n",
    "    print(f\"Weight statistics: ratio={ratio}\")\n",
    "\n",
    "    xgboost_classifier = XGBClassifier(enable_categorical=True)\n",
    "    randomized_search = RandomizedSearchCV(\n",
    "        xgboost_classifier, \n",
    "        parameters_grid, \n",
    "        cv=cross_val, \n",
    "        scoring=scoring, \n",
    "        n_jobs=n_jobs, \n",
    "        error_score=error_score, \n",
    "        verbose=verbose\n",
    "    )\n",
    "\n",
    "    randomized_search.fit(x, y)\n",
    "    best_params = randomized_search.best_params_\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "    cv_results_df = pd.DataFrame(randomized_search.cv_results_)\n",
    "    cv_results_file = f\"{dir}/data/xgboost_cv_results-v{version}.csv\"\n",
    "\n",
    "    cv_results_df.to_csv(cv_results_file, index=False)\n",
    "\n",
    "    return best_params, ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86e8a5dc-da33-48a7-9b6d-8bdb4fb223ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost_best(x, y, best_params, ratio, save_drive, version):\n",
    "    \"\"\"\n",
    "    Train an XGBoost model with the best hyperparameters.\n",
    "\n",
    "    Parameters:\n",
    "    - x (array-like): Input features.\n",
    "    - y (array-like): Labels.\n",
    "    - best_params (dict): Best hyperparameters.\n",
    "    - version (int): Current working version.\n",
    "\n",
    "    Returns:\n",
    "    - final_model: Trained XGBoost model.\n",
    "    \"\"\"\n",
    "    print(\"Final training with the best hyperparameters.\")\n",
    "    print(f\"Best hyperparameter configuration: {best_params}\")\n",
    "\n",
    "    # Input validation\n",
    "    if not isinstance(x, (np.ndarray, pd.DataFrame)):\n",
    "        print(\"Input 'x' must be a numpy array or a pandas DataFrame.\")\n",
    "        raise ValueError(\"Input 'x' must be a numpy array or a pandas DataFrame.\")\n",
    "    if not isinstance(y, (np.ndarray, pd.Series)):\n",
    "        print(\"Input 'y' must be a numpy array or a pandas DataFrame.\")\n",
    "        raise ValueError(\"Input 'y' must be a numpy array or a pandas Series.\")\n",
    "\n",
    "    # Initialize the model with the best hyperparameters\n",
    "    final_model = XGBClassifier(**best_params, enable_categorical=True)\n",
    "\n",
    "    try:\n",
    "        final_model.fit(x, y)\n",
    "        print(\"Final model training completed.\")\n",
    "\n",
    "        print(\"Getting feature importance..\")\n",
    "        feature_importance = final_model.feature_importances_\n",
    "        feature_names = x.columns\n",
    "\n",
    "        feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})\n",
    "        feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "        csv_file = f\"{save_drive}/xgboost_feature_importance-v{version}.csv\"\n",
    "        feature_importance_df.to_csv(csv_file, index=False)\n",
    "\n",
    "        print(f\"Feature importance saved in CSV file: {csv_file}\")\n",
    "\n",
    "        # Plot and save the top 10 features\n",
    "        top_10_feature_importance = feature_importance_df.head(10)\n",
    "        \n",
    "        plt.barh(top_10_feature_importance['Feature'], top_10_feature_importance['Importance'])\n",
    "        plt.title(\"Top 10 Important Features\")\n",
    "        save_plot_file = f\"{save_drive}/xgboost_top_10_feature_importance-v{version}.png\"\n",
    "        plt.savefig(save_plot_file, bbox_inches=\"tight\")\n",
    "\n",
    "        print(f\"Top 10 feature importance plot saved in {save_plot_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during final model training: {e}\")\n",
    "        raise\n",
    "\n",
    "    return final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ea19fa2-8106-4c90-bb7b-373c50ce9897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_xgboost(x, y, model, evaluate, project_dir, version):\n",
    "    try:\n",
    "        print(\"Making XGBoost Predictions...\")\n",
    "        predictions = model.predict(x)\n",
    "\n",
    "        if evaluate:\n",
    "            print(\"Evaluating XGBoost Model...\")\n",
    "            evaluate_model(y, predictions, title=\"XGBoost Test\", project_dir=project_dir, version=version)\n",
    "\n",
    "        return model\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during XGBoost model testing: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dd9949-5800-40c4-bc72-af8b14bde8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters Grid: {'n_estimators': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7f1f2899afe0>, 'subsample': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7f1f2899ae00>, 'max_depth': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7f1f2899b940>, 'colsample_bytree': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7f1f2899bc10>, 'min_child_weight': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7f1f2899b850>, 'gamma': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7f1f28998df0>, 'eta': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7f1f289982e0>}\n",
      "5-fold cross-validation\n",
      "Scoring strategy: accuracy\n",
      "Number of jobs to run in parallel: -1\n",
      "Error score: raise\n",
      "Verbosity: 10\n",
      "Weight statistics: positive instances=69\n",
      "Weight statistics: negative instances=277\n",
      "Weight statistics: ratio=4.0144927536231885\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "best_parameters, ratio = train_xgboost(x_train, y_train, parameters_grid=xgb_parameters_grid, version=VER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48517224-bcef-4e2c-bd9a-77a350187e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = train_xgboost_best(x_train, \n",
    "                                 y_train, \n",
    "                                 best_params=best_parameters, \n",
    "                                 ratio=ratio, \n",
    "                                 save_drive=f\"{project_dir}/output/\", \n",
    "                                 version=VER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1307261-7379-4e0e-9e03-f9251388ba9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model = test_xgboost(x_test, y_test, model=final_model, evaluate=True, project_dir=f\"{project_dir}/output/\", version=VER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d85764-6eff-4739-aa14-fb900620d161",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_model(model=xgboost_model,\n",
    "             model_name=f\"XGBoost Model-V{VER}\",\n",
    "             save_path=f\"{project_dir}/data/models/xgboost_model-v{VER}.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62372306-16c1-4888-ab8a-3bc41229a58c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
